---
output: html_document
editor_options: 
  chunk_output_type: console
---
# The Many Variables and the Spurious Waffles

This chapter discusses the "causal salad" issue that is really prevelant in epidemiology (and other sciences) right now. When you "adjust" for variables in models, what are you actually doing? What answers can you get from adjusting? How do you decide what variables should go into a model? We get to talk about confounding, which is one of my favorite subjects, and more generally, other types of biases. These are presented in the framework of graphical causal models using directed acyclic graphs (DAGs).

## Chapter notes



## Exercises

**5E1.** The linear models

$$\mu_i = \beta_x x_i + \beta_z z_i$$
and
$$\mu_i = \alpha + \beta_x x_i + \beta_z z_i$$

are both multiple regression models. The first model
$$\mu_i = \alpha + \beta x_i$$
is a simple linear regression model and while the third model
$$\left( \mu_i = \alpha + \beta (x_i - z_i) \right)$$
involves both $x$ and $z$, the model only has one coefficient and treats their difference as a single explanatory variable.

**5E2.** We could evaluate the claim *animal diversity is linearly related to latitude, but only after controlling for plant diversity* using the linear model
\begin{align*}
\text{animal diversity}_i &\sim \mathrm{Likelihood}\left( \mu_i \right) \\
\mu_i &= \alpha + \beta_1 \left( \mathrm{latitude} \right) + \beta_2 \left( \text{plant diversity} \right)
\end{align*}

where suitable priors are assigned and other appropriate parameters are given for the likelihood function.

**5E3.** We could evaluate the claim *neither amount of funding nor size of laboratory is by itself a good predictor of time to PhD degree; but together these variables are both positively associated with time to degree* using the multiple linear regression
\begin{align*}
\text{time to PhD}_i &\sim \mathrm{Likelihood}\left( \mu_i \right) \\
\mu_i &= \alpha + \beta_1 \left( \text{amount of funding} \right) + \beta_2 \left( \text{size of laboratory} \right)
\end{align*}

with suitable priors, etc. The slope of both $\beta_j$ should be positive. Classically, I would probably be inclined to include an interaction term in this model, but we haven't talked about that yet in the book so I didn't.

**5E4.** If we have a single categorical variable with levels $A,$ $B,$ $C,$ and $D,$ (represented as indicator variables), the following linear models are inferentially equivalent:
\begin{align*}
\mu_i &= \alpha + \beta_A A_i + \beta_B B_i + \beta_D D_i, \\
\mu_i &= \alpha + \beta_B B_i + \beta_C C_i + \beta_D D_i, \\
\mu_i &= \alpha_A A_i + \alpha_B B_i + \alpha_C C_i + \alpha_D D_i, \quad \text{ and }\\
\mu_i &= \alpha_A \left( 1 - B_i - C_i - D_i \right) + \alpha_B B_i + \alpha_C C_i + \alpha_D D_i.
\end{align*}

**5M1.** An example of a spurious correlation: I am happy on days when it is sunny outside, and when I get to leave work early. Both of these things individually make me happy, but the weather doesn't determine whether I get to leave work early. (At least not fully anyways. The weather definitely determines how much work I get done, but other external factors control the amount of work I have and the deadlines I need to meet.)

**5M2.** An example of a masked relationship: fill this in when I think of one.

**5M3.** I guess a higher divorce rate could cause a higher marriage rate by making more people available to be married. If divorced people tend to get remarried (potentially to non-divorced people), then the overall marriage rate could go up. Addressing this using a multiple linear regression model would be quite difficult, as you would need more data on remarriage and divorce status. It could be difficult to incorporate remarriages into the regression model, maybe an agent-based model would be more intuitive for this.

**5M4.** I found [this list](https://worldpopulationreview.com/state-rankings/mormon-population-by-state) of percent LDS population by state. So if we want to add this as a predictor to the divorce rate model, first I'll join these data to the WaffleDivorce data from the `rethinking` package.

```{r 5m4 data cleaning}
pct_lds <- readr::read_csv(here::here("static/pct_lds.csv"))

library(rethinking)
data("WaffleDivorce")

dat_5m4 <-
	dplyr::left_join(
		WaffleDivorce,
		pct_lds,
		by = c("Location" = "State")
	)

dat_5m4[
	which(dat_5m4$Location == "District of Columbia"),
	"mormonRate"
] <-0.0038

dat_5m4_l <-
	dat_5m4 |>
	dplyr::transmute(
		D = Divorce,
		M = Marriage,
		A = MedianAgeMarriage,
		L = mormonRate * 100
	) |>
	as.list()

layout(matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2))
purrr::walk2(dat_5m4_l, names(dat_5m4_l), ~hist(.x, main = .y, breaks = "FD"))
```

When I tried to do this the first time, it turns out that the WaffleDivorce dataset has D.C. in it, but not the state of Nevada? And the table of percent LDS populations I found has Nevada, but not D.C. So I just googled it, and on the Wikipedia page I saw that the percentage was 0.38% in 2014, which is good enough for government work, so I filled it in manually. I didn't transform any of the predictors, but standardizing and transforming them would probably be a good idea. I think a logit transformation would probably be suitable for the percent LDS population but as long as `quap()` converges I won't worry about it too much.

\begin{align*}
\text{Divorce rate}_i &\sim \mathrm{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 \cdot \text{Marriage rate}_i + \beta_2 \cdot \text{Median age at marriage}_i \\
&\quad\quad + \beta_3 \cdot \text{Percent LDS}_i \\
\beta_0 &\sim \mathrm{Unif}(0, 1000); \\
\beta_j &\sim \mathrm{Normal}(0, 10); \quad j = \{0, \ldots, 3\} \\
\sigma &\sim \mathrm{Exp}(0.5)
\end{align*}

where $i$ indexes the states. Since the outcome is in units of divorces per 1000 people, I decided to let the intercept be anything from 0 to 1000 people. It will probably be quite small but that shouldn't be too much of a problem I think. Then, I assigned weakly uninformative priors to the slope coefficients and a simple positive prior to the standard deviation. It would be better to do a prior predictive simulation and figure out some better assumptions. Now we'll fit th model with `quap` (quadratic approximation). 

```{r 5m4 fitting}
set.seed(100)
fit_5m4 <-
	rethinking::quap(
		flist = alist(
			D ~ dnorm(mu, sigma),
			# We could rewrite this so we didn't have to write out all the identical
			# priors but this is easier and I am lazy
			mu <- b0 + bM * M + bA * A + bL * L,
			b0 ~ dunif(0, 100),
			bM ~ dnorm(0, 10),
			bA ~ dnorm(0, 10),
			bL ~ dnorm(0, 10),
			sigma ~ dexp(0.5)
		),
		data = dat_5m4_l
	)

rethinking::precis(fit_5m4)
```

We can see that for every one percentage increase in the LDS population of a state, the model predicts that the divorce rate will decrease by -0.07 units. Since the divorce rate is in percentage units, this means we would need slightly less than a 15% increase in LDS population for a state's divorce rate to decrease by 1%.

This estimate is probably biased by Utah, which is a strong outlier with 63% LDS population (far more than the second highest state, Idaho, with 24% of the population identifying as LDS).






