{
  "hash": "71a02ade2c788d0f7cd280e232ce5d6b",
  "result": {
    "markdown": "# Week 2 Homework\n\nThis homework covers the material from Lectures 3 and 4, and the content from\nbook Chapter 4. The questions are reproduced almost identically from\n[Richard McElreath's original assignment](https://github.com/rmcelreath/stat_rethinking_2023/blob/main/homework/week02.pdf), I did not write them. I only wrote these solutions.\n\n::: {.callout-note appearance=\"simple\" icon=false}\n\n**1.** From the Howell1 dataset, consider only the people younger than 13\nyears old. Estimate the causal association between age and weight. Assume that\nage influences weight through two paths. First, age influences height, and\nheight influences weight. Second, age directly influences weight through\nage-related changes in muscle growth and body proportions.\n\nDraw the DAG that represents these causal relationships. And then write a\ngenerative simulation that takes age as an input and simulates height\nand weight, obeying the relationships in the DAG.\n\n:::\n\nOK, I will assume that the first paragraph is just an introduction to the\nhomework set and the actual task for this question is in the second paragraph.\nHere is the DAG for this problem.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the relationships in the DAG\ndag <-\n\tdagitty::dagitty(\n\t\t\"dag {\n\t\t\tage -> height -> weight\n\t\t\tage -> weight\n\t\t}\"\n\t)\n\n# Specify instructions for plotting the DAG, then do that\ndagitty::coordinates(dag) <-\n\tlist(\n\t\tx = c(age = 1, height = 2, weight = 2),\n\t\ty = c(age = 2, height = 3, weight = 1)\n\t)\nplot(dag)\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nNow we can write a generative simulation. First, let's look at the pairwise\ncorrelations so we can get sort of an idea of the data distributions and the\neffects we should simulate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rethinking)\ndata(Howell1)\nh1 <-\n\tHowell1 |>\n\tdplyr::filter(age < 13)\n\npairs(h1[1:3])\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nOk, so with that plot in mind we see that ages are discrete from 0 to 13,\nheight ranges from about 50 units to 150 units, and weight ranges from about\n5 units to 35 units. So our generative simulation should stay within those\nranges.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the seed so the simulation makes the same numbers every time\nset.seed(101)\n\n# This part does the simulation and puts it into a tibble for storage\nsim <- tibble::tibble(\n\t# Just randomly draw an age. In the original data the ages are not\n\t# 100% even but I think this is fine.\n\tage = sample(0:13, nrow(h1), replace = TRUE),\n\t# Height and weight simulations using dag relationships and made up numbers.\n\theight = rnorm(nrow(h1), 60 + 5 * age, 10),\n\tweight = rnorm(nrow(h1), 3 + 0.1 * age + 0.2 * height, 1)\n)\n\n# Put the columns into the same order for easier comparisons and plot\nsim <- sim[, c(\"height\", \"weight\", \"age\")]\npairs(sim)\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nI just randomly picked these numbers and fiddled with it a bit until the two\nplots looked similar, and I think I was able to get them pretty close for\nsuch a simple simulation using linear effects and normal errors.\n\n::: {.callout-note appearance=\"simple\" icon=false}\n\n**2.** Use a linear regression to estimate the **total** causal effect of\neach year of growth on weight.\n\n:::\n\nBased on the DAG, to obtain the **total** causal effect of a year of growth\n(the interpretation of the parameter associated with the independent\nvariable *age*) we want to use age as the only independent variable in the\nmodel. If we controlled for height, the parameter would estimate the\n**direct** causal effect of age, but we want the **total** effect. So the basic\nstructure of our model will look like this.\n\\begin{align*}\n\\text{weight}_i &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu &= \\alpha + \\beta \\cdot \\text{age}_i \\\\\n\\alpha &\\sim \\text{Prior}() \\\\\n\\beta &\\sim \\text{Prior}() \\\\\n\\sigma &\\sim \\text{Prior}()\n\\end{align*}\n\nWe will need to assign some priors to our data. In general, I tend to prefer\nweakly informative priors, whereas I think McElreath tends to prefer less\nbroad priors. I'll base my priors off the default recommended priors from\nthe [Stan devs' prior choice recommendations](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations).\nOf course they also recommend rescaling all variables before modeling, which\nI think is a good idea, but I won't do it here because I'm lazy and I don't\nthink it's going to be particularly useful here.\n\nOne additional constraint that we have is that the $\\alpha$ and $\\beta$\nparameters should both be **positive**!\nIt doesn't make sense for someone to shrink as they get older (at least not for\nages 0 to 13, maybe for seniors but not here). And it certainly doesn't make\nsense for someone to ever have a negative weight, even at age zero.\nSo we'll use a distribution that has to be positive. I'll choose a half-normal \ndistribution, which is easy to sample by just taking the absolute value of a\nrandom normal sample.\n\n\\begin{align*}\n\\text{weight}_i &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu &= \\alpha + \\beta \\cdot \\text{age}_i \\\\\n\\alpha &\\sim \\text{Half-Normal}(0, 5) \\\\\n\\beta &\\sim \\text{Half-Normal}(0, 5) \\\\\n\\sigma &\\sim \\text{Exponential}(0.2)\n\\end{align*}\n\nThese priors are quite weak, perhaps we should do a prior predictive check\nto visualize them before doing anything else.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(101)\npps <-\n\ttibble::tibble(\n\t\ta = abs(rnorm(1000, 0, 5)),\n\t\tb = abs(rnorm(1000, 0, 5)),\n\t\ts = rexp(1000, 0.2)\n\t)\n\nplot(\n\tNULL,\n\txlim = c(0, 13), ylim = c(-10, 150),\n\txlab = \"Age\", ylab = \"Simulated mu\",\n\tmain = \"Prior predictive simulation of E[weight | age]\"\n)\n\nfor (i in 1:nrow(pps)) {\n\tcurve(\n\t\tpps$a[i] + pps$b[i] * x,\n\t\tfrom = 0, to = 13, n = 1000,\n\t\tadd = TRUE, col = rethinking::col.alpha(\"black\", 0.1)\n\t)\n}\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWell, some of those are way too flat, and some of them are way too steep, but\noverall I think this encompasses a good range of possibilities. Let's also\nlook at the prior predictive distribution of the actual outcomes. Here, I'll\ntake random samples of age from a discrete uniform distribution. That's\nprobably not the best way to do it but it seems easiest.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Do the simulation\nset.seed(102)\nsim_age <- sample(0:13, 1000, replace = TRUE)\nsim_y <- rnorm(\n\t1000,\n\tmean = pps$a + pps$b * sim_age,\n\tsd = pps$s\n)\nlayout(matrix(c(1, 2), nrow = 1))\n\n# Histogram of all y values\nhist(\n\tsim_y,\n\txlab = \"Simulated outcome\",\n\tmain = \"Distribution of simulated weights\",\n\tbreaks = \"FD\"\n)\n\n# Plot showing y vs x with simulated regression lines as well\nplot(\n\tNULL,\n\txlim = c(0, 13), ylim = c(-10, 150),\n\txlab = \"Age\", ylab = \"Simulated weight\",\n\tmain = \"Simulated weights vs simulated ages\"\n)\nfor (i in 1:nrow(pps)) {\n\tcurve(\n\t\tpps$a[i] + pps$b[i] * x,\n\t\tfrom = 0, to = 13, n = 1000,\n\t\tadd = TRUE, col = rethinking::col.alpha(\"black\", 0.05)\n\t)\n}\npoints(sim_age, sim_y)\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWell, we ended up with a few negative and a few riduculously large heights,\nbut since we're just doing a linear regression here I think we can live with\nthat and let the data inform the golem that no one has negative heights.\nProbably we would want to either change the likelihood function or transform\nsomething (e.g. use a log link) to prevent any negative responses, but this\nwill probably wash out in the fitting. So let's do that.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <-\n\trethinking::quap(\n\t\tflist = alist(\n\t\t\tweight ~ dnorm(mu, sigma),\n\t\t\tmu <- a + b * age,\n\t\t\ta ~ dnorm(0, 5),\n\t\t\tb ~ dnorm(0, 5),\n\t\t\tsigma ~ dexp(0.2)\n\t\t),\n\t\tconstraints = alist(\n\t\t\ta = \"lower=0\",\n\t\t\tb = \"lower=0\"\n\t\t),\n\t\tdata = list(\n\t\t\tweight = h1$weight,\n\t\t\tage = h1$age\n\t\t)\n\t)\n```\n:::\n\n\nHmm. Looks like `quap` does not take a constraints argument the way I thought\nit did. So I guess we will just have to settle for exponential priors, which\nlike I mentioned, is probably the easiest way (not the best way) to get\na strictly positive prior. Let's redo the prior predictive simulation using\nthis model.\n\\begin{align*}\n\\text{weight}_i &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu &= \\alpha + \\beta \\cdot \\text{age}_i \\\\\n\\alpha &\\sim \\text{Exponential}(0.2) \\\\\n\\beta &\\sim \\text{Exponential}(0.2) \\\\\n\\sigma &\\sim \\text{Exponential}(0.2)\n\\end{align*}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(101)\npps <-\n\ttibble::tibble(\n\t\ta = rexp(1000, 0.2),\n\t\tb = rexp(1000, 0.2),\n\t\ts = rexp(1000, 0.2)\n\t)\n\nset.seed(102)\nsim_age <- sample(0:13, 1000, replace = TRUE)\nsim_y <- rnorm(\n\t1000,\n\tmean = pps$a + pps$b * sim_age,\n\tsd = pps$s\n)\n# Histogram of all y values\nhist(\n\tsim_y,\n\txlab = \"Simulated outcome\",\n\tmain = \"Distribution of simulated weights\",\n\tbreaks = \"FD\"\n)\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot showing y vs x with simulated regression lines as well\nplot(\n\tNULL,\n\txlim = c(0, 13), ylim = c(-10, 150),\n\txlab = \"Age\", ylab = \"Simulated weight\",\n\tmain = \"Simulated weights vs simulated ages\"\n)\nfor (i in 1:nrow(pps)) {\n\tcurve(\n\t\tpps$a[i] + pps$b[i] * x,\n\t\tfrom = 0, to = 13, n = 1000,\n\t\tadd = TRUE, col = rethinking::col.alpha(\"black\", 0.05)\n\t)\n}\npoints(sim_age, sim_y)\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\nYes, this definitely results in a more left-skewed distribution, but I think\nit will work out fine in the model (like before). So I'm not too pressed about\nit. Now let's finally fit the model, for real.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <-\n\trethinking::quap(\n\t\tflist = alist(\n\t\t\tweight ~ dnorm(mu, sigma),\n\t\t\tmu <- a + b * age,\n\t\t\ta ~ dexp(0.2),\n\t\t\tb ~ dexp(0.2),\n\t\t\tsigma ~ dexp(0.2)\n\t\t),\n\t\tdata = list(\n\t\t\tweight = h1$weight,\n\t\t\tage = h1$age\n\t\t)\n\t)\n\nrethinking::precis(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          mean         sd     5.5%    94.5%\na     7.423126 0.36170953 6.845044 8.001208\nb     1.344382 0.05471435 1.256938 1.431826\nsigma 2.519828 0.14708546 2.284757 2.754899\n```\n:::\n:::\n\n\nSo our estimate for the total causal effect of age on weight is 1.34. In other words, we would expect that the average\nindividual is born at weight 7.42 units,\nand increases in weight by 1.34 units each\nyear.\n\n::: {.callout-note appearance=\"simple\" icon=false}\n\n**3.** Now suppose the causal association between age and weight might be\ndifferent for boys and girls. Use a single linear regression, with a\ncategorical variable for sex, to estimate the total causal effect of age on\nweight separately for boys and girls. How do girls and boys differ? Provide\none or more posterior contrasts as a summary.\n\n:::\n\nSo what we are assuming here is that the effect of age is different for\nmales and females -- I am not sure whether there is a difference in\nweight at birth for males and females, so I will say for simplicity that\nthere is not. We'll use a similar model from before, but this time the\neffect of age will be dependent on sex.\n\n\\begin{align*}\n\\text{weight}_i &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu &= \\alpha_{i} + \\beta \\cdot \\text{age}_{\\text{Sex}_i} \\\\\n\\alpha &\\sim \\text{Exponential}(0.2) \\\\\n\\beta_{j} &\\sim \\text{Exponential}(0.2) \\\\\n\\sigma &\\sim \\text{Exponential}(0.2)\n\\end{align*}\n\nSo now we will fit the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(100)\nfit2 <-\n\trethinking::quap(\n\t\tflist = alist(\n\t\t\tweight ~ dnorm(mu, sigma),\n\t\t\tmu <- a + b[sex] * age,\n\t\t\ta ~ dexp(0.2),\n\t\t\tb[sex] ~ dexp(0.2),\n\t\t\tsigma ~ dexp(0.2)\n\t\t),\n\t\tdata = list(\n\t\t\tweight = h1$weight,\n\t\t\tage = h1$age,\n\t\t\t# We have to add 1 for the index coding to work right\n\t\t\tsex = h1$male + 1\n\t\t),\n\t\tstart = list(a = 0.5, b = c(1, 1), sigma = 0.5)\n\t)\n\nrethinking::precis(fit2, depth = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          mean         sd     5.5%    94.5%\na     7.430799 0.34899528 6.873037 7.988561\nb[1]  1.243728 0.06086206 1.146459 1.340998\nb[2]  1.444553 0.06101328 1.347042 1.542064\nsigma 2.431267 0.14192809 2.204438 2.658095\n```\n:::\n:::\n\n\nOk, so I had some issues with the start values here. Probably because\nthe priors are very diffuse, quap sometimes cannot get to the MAP from\nrandomly sampled starting locations. However, I just had to find a seed that\nworks, because it seems to be ignoring the start value for b (or I am\nspecifying it incorrectly) in the error messages I get. But this one fit,\nso let's go. There appears to be a slight difference between the two\nslope parameters, but we cannot allow ourselves to be mislead by the table of coefficients. We must compute the contrast distribution to truly understand\nwhat is happening here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npost <- extract.samples(fit2, n = 1000)\npost$contrast <- post$b[, 2] - post$b[, 1]\n\nlayout(matrix(c(1, 2), nrow = 1))\n\n# Plot of posterior means\nplot(\n\tNULL,\n\txlim = c(-0.1, 2), ylim = c(0, 10),\n\txlab = \"Posterior mean effect of age on weight (kg/year)\",\n\tylab = \"Density\",\n\txaxs = \"i\", yaxs = \"i\"\n)\n\nrethinking::dens(post$b[, 2], col = \"dodgerblue2\", lwd = 2, add = TRUE)\nrethinking::dens(post$b[, 1], col = \"hotpink1\", lwd = 2, add = TRUE)\nrethinking::dens(post$contrast, col = \"black\", lwd = 2, add = TRUE)\nlegend(\n\tx = \"topleft\",\n\tlegend = c(\"Males\", \"Females\", \"Contrast\"),\n\tcol = c(\"dodgerblue2\", \"hotpink1\", \"black\"),\n\tlwd = c(2, 2, 2)\n)\n\n# Plot of regression lines from posterior\nplot(\n\tNULL,\n\txlim = c(0, 13),\n\tylim = c(0, 30),\n\txlab = \"Age\",\n\tylab = \"Predicted weight (kg)\"\n)\n\nfor (i in 1:length(post$a)) {\n\tcurve(\n\t\tpost$a[i] + post$b[i, 1] * x,\n\t\tfrom = 0, to = 13, add = TRUE,\n\t\tcol = rethinking::col.alpha(\"hotpink1\", 0.01)\n\t)\n}\n\nfor (i in 1:length(post$a)) {\n\tcurve(\n\t\tpost$a[i] + post$b[i, 2] * x,\n\t\tfrom = 0, to = 13, add = TRUE,\n\t\tcol = rethinking::col.alpha(\"dodgerblue2\", 0.01)\n\t)\n}\n\nfor (i in 1:length(post$a)) {\n\tcurve(\n\t\tpost$a[i] + (post$b[i, 2] - post$b[i, 1]) * x,\n\t\tfrom = 0, to = 13, add = TRUE,\n\t\tcol = rethinking::col.alpha(\"black\", 0.01)\n\t)\n}\n```\n\n::: {.cell-output-display}\n![](week2_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n::: {.callout-note appearance=\"simple\" icon=false}\n\n**4.** The data in `data(Oxboys)` are growth records for 26 boys measured\nover 9 periods. I want you to model their growth. Specifically, model the\nincrements in growth from one `Occassion` to the next. Each increment is simply\nthe difference between height in one occasion and height in the previous\noccasion. Since none of these boys shrunk during the study, all of the growth\nincrements are greater than zero. Estimate the posterior distribution of\nthese increments. Constrain the distribution so it is always positive -- it\nshould not be possible for the model to think that boys can shrink from year\nto year. Finally computer the posterior distribution of the total growth over\nall 9 occasions.\n\n:::\n\n<!-- END OF FILE -->\n",
    "supporting": [
      "week2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}